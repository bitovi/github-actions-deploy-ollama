name: 'Deploy Ollama and Open WebUI'
description: 'Deploy your own LLM (large language model) like llama3 with a web based UI to an EC2 instance.'

inputs:
  # App specific config
  disable_signup:
    description: 'Disable user signup for the application.'
    required: false
    default: 'false'
  ollama_models:
    description: 'Comma separated list of models to download automatically.'
    required: false
    default: ''

  # AWS Configuration
  aws_access_key_id:
    description: 'AWS access key ID'
    required: false
  aws_secret_access_key:
    description: 'AWS secret access key'
    required: false
  aws_session_token:
    description: 'AWS session token'
    required: false
  aws_default_region:
    description: 'AWS default region'
    default: us-east-1
    required: false
  aws_resource_identifier:
    description: 'Set to override the AWS resource identifier for the deployment.  Defaults to `${org}-{repo}-{branch}`.  Use with destroy to destroy specific resources.'
    required: false
  aws_additional_tags: # additional_tags
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false

  # GitHub Commons main inputs
  checkout:
    description: 'Specifies if this action should checkout the code'
    required: false
    default: 'true'
  tf_stack_destroy:
    description: 'Whether to destroy the Terraform stack on completion.'
    required: false
    default: 'false'
  tf_state_file_name:
    description: 'The name of the Terraform state file.'
    required: true
  tf_state_file_name_append:
    description: 'Append a suffix to the state file name to allow unique state management.'
    required: false
  tf_state_bucket:
    description: 'The S3 bucket name where the Terraform state file will be stored.'
    required: true
  tf_state_bucket_destroy:
    description: 'Whether to destroy the state bucket on stack completion.'
    required: false
  ansible_ssh_to_private_ip:
    description: 'Make Ansible connect to the private IP of the instance. Only usefull if using a hosted runner in the same network.'
    required: false
  ansible_start_docker_timeout:
    description: 'Ammount of time in seconds it takes Ansible to mark as failed the startup of docker. Defaults to `300`'
    required: false
    default: 6000

  # ENV files
  env_aws_secret:
    description: 'Secret name to pull env variables from AWS Secret Manager, could be a comma separated list, read in order. Expected JSON content.'
    required: false
  env_repo:
    description: 'File containing environment variables to be used with the app'
    required: false
  env_ghs:
    description: 'GitHub Secret Name containing `.env` file style to be used with the app.'
    required: false
  env_ghv:
    description: 'GitHub Variable Name containing `.env` file style to be used with the app.'
    required: false

  # EC2 Instance config
  aws_ec2_ami_filter:
    description: 'AWS AMI Filter string. Will be used to lookup for lates image based on the string. Defaults to `ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*`.'
    required: false
  aws_ec2_ami_owner:
    description: 'Owner of AWS AMI image. This ensures the provider is the one we are looking for. Defaults to `099720109477`, Canonical (Ubuntu).'
    required: false
  aws_ec2_ami_id: # aws_ami_id
    description: 'AWS AMI ID. Will default to lookup for latest image of the `aws_ec2_ami_filter` string. This will override `aws_ec2_ami_filter` lookup.'
    required: false
  aws_ec2_ami_update:
    description: 'Set this to true if you want to recreate the EC2 instance if there is a newer version of the AMI.'
    required: false
  aws_ec2_iam_instance_profile: # aws_ec2_instance_profile
    description: 'The AWS IAM instance profile to use for the EC2 instance'
    required: false
  aws_ec2_instance_type:
    description: 'Type of AWS EC2 instance to deploy.'
    required: false
    default: 'inf1.xlarge'
  aws_ec2_instance_root_vol_size: # ec2_volume_size
    description: 'Define the volume size (in GiB) for the root volume on the AWS Instance.'
    default: '20'
    required: false
  aws_ec2_instance_root_vol_preserve:
    description: 'Set this to true to avoid deletion of root volume on termination. Defaults to false.'
    required: false
  aws_ec2_security_group_name:
    description: 'The name of the EC2 security group'
    required: false
  aws_ec2_create_keypair_sm:
    description: 'Create a key pair using AWS Secrets Manager.'
    required: false
  aws_ec2_instance_public_ip:
    description: 'Add a public IP to the instance or not. (Not an Elastic IP)'
    required: false
    default: true
  aws_ec2_port_list:
    description: 'List of ports to be enabled as an ingress rule in the EC2 SG, in a [xx,yy] format - Not the ELB'
    required: false
  aws_ec2_additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false

  # AWS VPC Inputs
  aws_vpc_create:
    description: 'Define if a VPC should be created'
    required: false
  aws_vpc_name:
    description: 'Set a specific name for the VPC'
    required: false
  aws_vpc_cidr_block:
    description: 'Define Base CIDR block which is divided into subnet CIDR blocks. Defaults to 10.0.0.0/16.'
    required: false
  aws_vpc_public_subnets:
    description: 'Comma separated list of public subnets. Defaults to 10.10.110.0/24'
    required: false
  aws_vpc_private_subnets:
    description: 'Comma separated list of private subnets. If none, none will be created.'
    required: false
  aws_vpc_availability_zones:
    description: 'Comma separated list of availability zones. Defaults to `aws_default_region.'
    required: false
  aws_vpc_id:
    description: 'AWS VPC ID. Accepts `vpc-###` values.'
    required: false
  aws_vpc_subnet_id:
    description: 'Specify a Subnet to be used with the instance. If none provided, will pick one.'
    required: false
  aws_vpc_enable_nat_gateway:
    description: 'Enables NAT gateway'
    required: false
  aws_vpc_single_nat_gateway:
    description: 'Creates only one NAT gateway'
    required: false
  aws_vpc_external_nat_ip_ids:
    description: 'Comma separated list of IP IDS to reuse in the NAT gateways'
    required: false
  aws_vpc_additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false

  # AWS Route53 Domains abd Certificates
  aws_r53_enable:
    description: 'Enables the usage of Route53 to manage DNS records.'
    required: false
  aws_r53_domain_name: # domain_name
    description: 'Define the root domain name for the application. e.g. app.com'
    required: false
  aws_r53_sub_domain_name: # sub_domain
    description: 'Define the sub-domain part of the URL. Defaults to `${org}-${repo}-{branch}`'
  aws_r53_root_domain_deploy: # root_domain
    description: 'Deploy to root domain. Will generate two DNS recrods, one for root, another for www'
    required: false
  aws_r53_enable_cert: # no_cert
    description: 'Makes the application use a certificate by enabling a certificate lookup.'
    required: false
    default: true # Legacy enable
  aws_r53_cert_arn: # cert_arn
    description: 'Define the certificate ARN to use for the application'
    required: false
  aws_r53_create_root_cert: # create_root_cert
    description: 'Generates and manage the root cert for the application'
    required: false
  aws_r53_create_sub_cert: # create_sub_cert
    description: 'Generates and manage the sub-domain certificate for the application'
    required: false
  aws_r53_additional_tags:
    description: 'A JSON object of additional tags that will be included on created resources. Example: `{"key1": "value1", "key2": "value2"}`'
    required: false

  # Docker 
  docker_remove_orphans:
    description: 'Toggle --remove-orphans flag. Defaults to false.'
    required: false
  docker_full_cleanup: 
    description: 'Set to true to run docker-compose down and docker system prune --all --force --volumes after.'
    required: false
  docker_repo_app_directory_cleanup: # app_directory_cleanup
    description: 'Will generate a timestamped compressed file and delete the app repo directory.'
    required: false
  docker_cloudwatch_enable:
    description: 'Toggle cloudwatch creation for Docker containers.'
    required: false
    default: true
  docker_cloudwatch_lg_name:
    description: 'Log group name. Will default to aws_identifier if none.'
    required: false
  docker_cloudwatch_skip_destroy:
    description: 'Toggle deletion or not when destroying the stack.'
    required: false
  docker_cloudwatch_retention_days:
    description: 'Number of days to retain logs. 0 to never expire.'
    required: false

outputs:
  # VPC
  aws_vpc_id:
    description: "The selected VPC ID used."
    value: ${{ steps.deploy.outputs.aws_vpc_id }}
  # EC2
  vm_url:
    description: "The URL of the generated app"
    value: ${{ steps.deploy.outputs.vm_url }}
  instance_endpoint:
    description: "The URL of the generated ec2 instance"
    value: ${{ steps.deploy.outputs.instance_endpoint }}
  ec2_sg_id:
    description: "SG ID for the EC2 instance"
    value: ${{ steps.deploy.outputs.ec2_sg_id }}

runs:
  using: 'composite'
  steps:
    - name: Checkout if required
      if: ${{ inputs.checkout == 'true' }}
      uses: actions/checkout@v4

    # - name: Copy User Files
    #   if: ${{ inputs.infrastructure_only == 'false' }}
    #   shell: bash
    #   env:
    #     GITHUB_ACTION_PATH: ${{ github.action_path }}
    #   run: |
    #     echo "Copying User Files"

    #     new_path=$GITHUB_ACTION_PATH/some-meaningfully-named-directory
    #     mkdir -p $new_path
    #     cp $GITHUB_WORKSPACE/${{ inputs.app_volume_ui }}/* "$new_path"

    - name: Copy Deployment Config
      if: ${{ inputs.infrastructure_only == 'false' }}
      shell: bash
      env:
        GITHUB_ACTION_PATH: ${{ github.action_path }}
        APP_SUBDIR: gha-deployment
      run: |
        app_path=$GITHUB_WORKSPACE/$APP_SUBDIR

        echo "Copying app Repo"
        mkdir -p "$app_path"
        cp -r  $GITHUB_ACTION_PATH/. "$app_path"

        echo "removing operations dir"
        rm -rf $app_path/operations

    # if inputs.disable_signup == 'true, then remove the signup page
    # env var: ENABLE_SIGNUP=false
    - name: Set app env config
      id: set-app-env-config
      shell: bash
      env:
        GITHUB_ACTION_PATH: ${{ github.action_path }}
        APP_SUBDIR: gha-deployment
        DISABLE_SIGNUP: ${{ inputs.disable_signup }}
        OLLAMA_MODELS: ${{ inputs.ollama_models }} 
      run: |
        app_path=$GITHUB_WORKSPACE/$APP_SUBDIR
        filename="auto.gha.app.env"

        echo "::group::Set up GHA generated app config"
        touch $app_path/$filename
        echo "checking if disable_signup is set ($DISABLE_SIGNUP)"
        if [ "$DISABLE_SIGNUP" == "true" ]; then
          echo "Disabling signup"
          echo "ENABLE_SIGNUP=false" >> $app_path/$filename
        else
          echo "Enabling signup"
          echo "ENABLE_SIGNUP=true" >> $app_path/$filename
        fi
        
        echo "checking if ollama_models is not empty and has more than one character."
        if [[ -n "$OLLAMA_MODELS" && ${#OLLAMA_MODELS} -gt 1 ]]; then
          echo "MODELS=$OLLAMA_MODELS" >> $app_path/$filename
        fi
        echo ""
        echo "::endgroup::"

    - name: Deploy with Bitovi Commons
      id: deploy
      uses: bitovi/github-actions-commons@v1
      with:
        # AWS Specific
        aws_access_key_id: ${{ inputs.aws_access_key_id }}
        aws_secret_access_key: ${{ inputs.aws_secret_access_key }}
        aws_session_token: ${{ inputs.aws_session_token }}
        aws_default_region: ${{ inputs.aws_default_region }}
        aws_resource_identifier: ${{ inputs.aws_resource_identifier }}
        aws_additional_tags: ${{ inputs.aws_additional_tags }}

        # Action main inputs
        gh_action_repo: ${{ github.action_path }}
        checkout: false
        tf_stack_destroy: ${{ inputs.tf_stack_destroy }}
        tf_state_file_name: ${{ inputs.tf_state_file_name }}
        tf_state_file_name_append: ${{ inputs.tf_state_file_name_append }}
        tf_state_bucket: ${{ inputs.tf_state_bucket }}
        tf_state_bucket_destroy: ${{ inputs.tf_state_bucket_destroy }}
        ansible_ssh_to_private_ip: ${{ inputs.ansible_ssh_to_private_ip }}
        ansible_start_docker_timeout: ${{ inputs.ansible_start_docker_timeout }}

        # ENV files
        env_aws_secret: ${{ inputs.env_aws_secret }}
        env_repo: ${{ inputs.env_repo }}
        env_ghs: ${{ inputs.env_ghs }}
        env_ghv: ${{ inputs.env_ghv }}

        # EC2
        aws_ec2_ami_filter: ${{ inputs.aws_ec2_ami_filter }}
        aws_ec2_ami_owner: ${{ inputs.aws_ec2_ami_owner }}
        aws_ec2_ami_id: ${{ inputs.aws_ec2_ami_id || inputs.aws_ami_id }}
        aws_ec2_ami_update: ${{ inputs. aws_ec2_ami_update }}
        aws_ec2_iam_instance_profile: ${{ inputs.aws_ec2_iam_instance_profile || inputs.ec2_instance_profile }}
        aws_ec2_instance_type : ${{ inputs.aws_ec2_instance_type || inputs.ec2_instance_type }} 
        aws_ec2_instance_root_vol_size: ${{ inputs.aws_ec2_instance_root_vol_size || inputs.ec2_volume_size }}
        aws_ec2_instance_root_vol_preserve: ${{ inputs.aws_ec2_instance_root_vol_preserve }}
        aws_ec2_security_group_name: ${{ inputs.aws_ec2_security_group_name }}
        aws_ec2_create_keypair_sm: ${{ inputs.aws_ec2_create_keypair_sm || inputs.create_keypair_sm_entry }}
        aws_ec2_instance_public_ip: ${{ inputs.aws_ec2_instance_public_ip }}
        aws_ec2_port_list: ${{ inputs.aws_ec2_port_list }}
        aws_ec2_user_data_file: ${{ inputs.aws_ec2_user_data_file }}
        aws_ec2_user_data_replace_on_change: ${{ inputs.aws_ec2_user_data_replace_on_change }}
        aws_ec2_additional_tags: ${{ inputs.aws_ec2_additional_tags }}
        # aws_ec2_port_list: "3011,11434" # Only usefull if exposing instance ports

        ## AWS VPC
        aws_vpc_create: ${{ inputs.aws_vpc_create }}
        aws_vpc_name: ${{ inputs.aws_vpc_name }}
        aws_vpc_cidr_block: ${{ inputs.aws_vpc_cidr_block }}
        aws_vpc_public_subnets: ${{ inputs.aws_vpc_public_subnets }}
        aws_vpc_private_subnets: ${{ inputs.aws_vpc_private_subnets }}
        aws_vpc_availability_zones: ${{ inputs.aws_vpc_availability_zones }}
        aws_vpc_id: ${{ inputs.aws_vpc_id }}
        aws_vpc_subnet_id: ${{ inputs.aws_vpc_subnet_id }}
        aws_vpc_enable_nat_gateway: ${{ inputs.aws_vpc_enable_nat_gateway }}
        aws_vpc_single_nat_gateway: ${{ inputs.aws_vpc_single_nat_gateway }}
        aws_vpc_external_nat_ip_ids: ${{ inputs.aws_vpc_external_nat_ip_ids }}
        aws_vpc_additional_tags: ${{ inputs.aws_vpc_additional_tags }}

        # AWS Route53 Domains abd Certificates
        aws_r53_enable: ${{ inputs.aws_r53_enable }}
        aws_r53_domain_name: ${{ inputs.aws_r53_domain_name || inputs.domain_name }}
        aws_r53_sub_domain_name: ${{ inputs.aws_r53_sub_domain_name || inputs.sub_domain }}
        aws_r53_root_domain_deploy: ${{ inputs.aws_r53_root_domain_deploy || inputs.root_domain }}
        aws_r53_enable_cert: ${{ inputs.aws_r53_enable_cert }}
        aws_r53_cert_arn: ${{ inputs.aws_r53_cert_arn || inputs.cert_arn }}
        aws_r53_create_root_cert: ${{ inputs.aws_r53_create_root_cert || inputs.create_root_cert }}
        aws_r53_create_sub_cert: ${{ inputs.aws_r53_create_sub_cert || inputs.create_sub_cert }}
        aws_r53_additional_tags: ${{ inputs.aws_r53_additional_tags }}

        # Docker
        docker_remove_orphans: ${{ inputs.docker_remove_orphans }}
        docker_full_cleanup: ${{ inputs.docker_full_cleanup }}
        docker_repo_app_directory: 'gha-deployment'
        docker_repo_app_directory_cleanup: ${{ inputs.docker_repo_app_directory_cleanup || inputs.app_directory_cleanup }}
        docker_cloudwatch_enable: ${{ inputs.docker_cloudwatch_enable }}
        docker_cloudwatch_lg_name: ${{ inputs.docker_cloudwatch_lg_name }}
        docker_cloudwatch_skip_destroy: ${{ inputs.docker_cloudwatch_skip_destroy }}
        docker_cloudwatch_retention_days: ${{ inputs.docker_cloudwatch_retention_days }}

        # AWS ELB
        aws_elb_create: true
        aws_elb_listen_port: "3011,11434"
        aws_elb_app_port: "3011,11434"
        aws_elb_healthcheck: "TCP:11434"